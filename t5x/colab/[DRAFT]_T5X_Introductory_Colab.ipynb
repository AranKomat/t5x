{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0BQWhvAP2jb"
      },
      "source": [
        "\u003c!--BEGIN GOOGLE-INTERNAL--\u003e\n",
        "**GOOGLERS: To run internally, you will need to connect to a Brain Frameworks (TPU) Colab runtime. **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqZYp90PIa1t"
      },
      "source": [
        "# Overview\n",
        "\n",
        "T5X is a modular, composable, research-friendly framework for high-performance, configurable, self-service training, evaluation, and inference of sequence models (starting with language) at many scales.\n",
        "\n",
        "It is essentially a new and improved implementation of the [T5 codebase](https://g3doc.corp.google.com/third_party/py/t5/README.md?cl=head) (based on Mesh TensorFlow) in JAX and Flax.\n",
        "\n",
        "# Getting Started\n",
        "\n",
        "In the following sections, we present 4 quick tutorials to get you started with common use-cases on T5X:\n",
        "\n",
        "1.)    **[DRAFT]** *Fine-tuning a Model:* This tutorial outlines the steps to fine-tune an existing pre-trained model with T5X on common downstream tasks/mixtures available on [SeqIO](go/seqio). This is one of the simplest and most common use cases of T5X. If you're new to T5X, this tutorial is the recommended starting point.\n",
        "\n",
        "2.)    **[DRAFT]** *Running Evaluation on a Model:* This tutorial outlines the steps to evaluate a model with T5X on downstream tasks/mixtures defined in SeqIO.\n",
        "\n",
        "\n",
        "3.)    **[DRAFT]** *Running Inference on a Model:* this tutorial outlines the steps to run inference on a model with T5X.\n",
        "\n",
        "4.)    **[DRAFT]** *Training a Model from Scratch:* this tutorial outlines the steps to pretrain a model with T5X on tasks/mixtures defined in SeqIO.\n",
        "\n",
        "\n",
        "\n",
        "**Note: Please run the \"Set-up\" section before beginning any of the tutorial sections.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUnSph76-5l5"
      },
      "source": [
        "# Set-up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEHO720H-9HX"
      },
      "source": [
        "In the following section, we import all required modules and define two helper functions that will allow us to easily parse gin configs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "My_5idETFxA2"
      },
      "outputs": [],
      "source": [
        "from typing import Sequence\n",
        "import os\n",
        "import re\n",
        "\n",
        "import gin\n",
        "import seqio\n",
        "import functools\n",
        "from google3.pyglib import gfile\n",
        "from colabtools import adhoc_import\n",
        "from colabtools import googlelog\n",
        "with adhoc_import.Google3SubmittedChangelist(build_targets=['//t5x:train', '//t5x:eval', '//t5x:infer']):\n",
        "  import t5x\n",
        "  from t5x import train as train_lib\n",
        "  from t5x.train import train \n",
        "  from t5x import eval as eval_lib\n",
        "  from t5x.eval import evaluate \n",
        "  from t5x import infer as infer_script\n",
        "  from t5x.infer import infer \n",
        "  from t5x import gin_utils\n",
        "  from t5.data import mixtures\n",
        "  from t5x import adafactor\n",
        "  from t5x import examples\n",
        "  from t5x.examples.t5 import network\n",
        "  from t5x import utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWnpe-7_5Exy"
      },
      "source": [
        "Below, we define a helper function that parses a Gin config string and any additional gin bindings. If you're not familiar with Gin, reading the [T5X Gin Primer](https://g3doc.corp.google.com/t5x/g3doc/usage/gin.md?cl=head) is recommended."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAy_mfcmhvn6"
      },
      "outputs": [],
      "source": [
        "def parse_gin_strings(gin_search_paths: Sequence[str],\n",
        "                      gin_file_str: str,\n",
        "                      gin_bindings: Sequence[str],\n",
        "                      skip_unknown: bool = False,\n",
        "                      finalize_config: bool = True):\n",
        "  \"\"\"Parses provided gin files override params.\n",
        "\n",
        "  Args:\n",
        "    gin_search_paths: paths that will be searched for gin files.\n",
        "    gin_file_strs: gin configs to be parsed. Strings will be parsed in order \n",
        "      with conflicting settings being overriden by later configs. Paths may\n",
        "      be relative to paths in `gin_search_paths`.\n",
        "    gin_bindings: individual gin bindings to be applied after the gin configs are\n",
        "      parsed. Will be applied in order with conflicting settings being overriden\n",
        "      by later opens.\n",
        "    skip_unknown: whether to ignore unknown bindings or raise an error (default\n",
        "      behavior).\n",
        "    finalize_config: whether to finalize the config so that it cannot be\n",
        "      modified (default behavior).\n",
        "  \"\"\"\n",
        "  # Register .gin file search paths with gin\n",
        "  for search_path in gin_search_paths:\n",
        "    gin.add_config_file_search_path(search_path)\n",
        "\n",
        "  # Parse config string and bindings.\n",
        "  gin.parse_config(gin_file_str, skip_unknown)\n",
        "  gin.parse_config(gin_bindings, skip_unknown)\n",
        "  logging.info('Gin Configuration:\\n%s', gin.config_str())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrs5pxUQN-3O"
      },
      "source": [
        "This code snippet defines a helper function, `parse_gin_and_get_configurable_fn`; this helper takes in a function that is configurable with gin, such as the fine-tuning `train` function. It then parses the parameters of our finetuning experiment to configure the function with Gin, and returns the fully configured function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKw81sfuEHMl"
      },
      "outputs": [],
      "source": [
        "def parse_gin_and_get_configurable_fn(configurable_fn,\n",
        "                                      gin_config_str=\"\",\n",
        "                                      gin_file_paths=[],\n",
        "                                      gin_bindings=[],\n",
        "                                      gin_search_paths=['.'],\n",
        "                                      tfds_data_dir=None,\n",
        "                                      seqio_additional_cache_dirs=[]):\n",
        "  '''\n",
        "  Args:\n",
        "    configurable_fn: a function that is configurable with Gin. We will return an\n",
        "      instance of this function that has been configured with the provided Gin \n",
        "      config.\n",
        "    gin_config_str: a string representing the gin config file to be parsed.\n",
        "    gin_file_paths: Path to gin configuration files. Multiple paths may be \n",
        "      passed and will be imported in the given order, with later configurations \n",
        "      overriding earlier ones.\n",
        "    gin_bindings: Individual gin bindings. The `MODEL_DIR` gin_binding will be \n",
        "      added to this list.\n",
        "    gin_search_paths: Comma-separated list of gin config path prefixes to be \n",
        "      prepended to suffixes given via `--gin_file`. Only the first prefix that \n",
        "      produces a valid path for each suffix will be used.\n",
        "    tfds_data_dir: If set, this directory will be used to store datasets \n",
        "      prepared by TensorFlow Datasets that are not available in the public TFDS \n",
        "      GCS bucket. Note that this flag overrides the `tfds_data_dir` attribute of\n",
        "      all `Task`s.\n",
        "    seqio_additional_cache_dirs: Directories to search for cached Tasks in \n",
        "      addition to defaults.\n",
        "\n",
        "    One of gin_config_str or gin_file_paths must be provided.\n",
        "  '''\n",
        "  if len(gin_config_str) == 0 and len(gin_file_paths) == 0:\n",
        "    return ValueError(\"One of `gin_config_str` or `gin_file_paths` must be provided.\")\n",
        "\n",
        "  with googlelog.Capture():\n",
        "    if tfds_data_dir:\n",
        "      seqio.set_tfds_data_dir_override(tfds_data_dir)\n",
        "    seqio.add_global_cache_dirs(seqio_additional_cache_dirs)\n",
        "\n",
        "    # Create gin-configurable version of `evaluate`.\n",
        "    fn_using_gin = gin.configurable(configurable_fn)\n",
        "\n",
        "    default_gin_search_paths = [\n",
        "      \"/google_src/head/depot/google3/\",\n",
        "      \"/google_src/head/depot/google3/t5x/\",\n",
        "      \"/google_src/head/depot/google3/t5x/examples/t5/t5_1_1/small.gin\",\n",
        "      \"/google_src/head/depot/google3/t5x/configs/runs/finetune.gin\",\n",
        "    ]\n",
        "    # User-provided gin paths take precedence if relative paths conflict.\n",
        "    gin_search_paths = gin_search_paths + default_gin_search_paths\n",
        "\n",
        "    with gin.unlock_config():\n",
        "      if len(gin_config_str) \u003e 0:\n",
        "        print(\"Parsing the provided gin_config_str and ignoring all provided gin file paths.\")\n",
        "        parse_gin_strings(\n",
        "            gin_search_paths,\n",
        "            gin_config_str,\n",
        "            gin_bindings\n",
        "        )\n",
        "      else:\n",
        "        print(\"Parsing the provided gin file paths and ignoring any provided gin_config_str.\")\n",
        "        gin_utils.parse_gin_flags(\n",
        "            gin_search_paths,\n",
        "            gin_file_paths,\n",
        "            gin_bindings\n",
        "        )\n",
        "    return fn_using_gin\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCVAdUsH3DFM"
      },
      "source": [
        "# Finetune a Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fvn_8W7JGLub"
      },
      "source": [
        "This section outlines the steps to fine-tune an existing pre-trained model with T5X on common downstream tasks defined with [SeqIO](go/seqio). This is one of the simplest and most common use cases of T5X. \n",
        "\n",
        "Fine-tuning a model with T5X consists of the following steps:\n",
        "\n",
        "1.   Choose the pre-trained model to fine-tune.\n",
        "2.   Choose the SeqIO Task/Mixture to fine-tune the model on.\n",
        "3.   Write a Gin file that configures the pre-trained model, SeqIO Task/Mixture and other details of your fine-tuning run.\n",
        "4.   Launch your experiment locally.\n",
        "\n",
        "\n",
        "These steps are explained in detail in the following sections. An example run that fine-tunes a T5-small checkpoint on WMT14 English to German translation benchmark is also showcased.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVgMKSNkIB4L"
      },
      "source": [
        "## Step 1: Choose a pre-trained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKRW4ASQyJ2X"
      },
      "source": [
        "To use a pre-trained model, you need a Gin config file that defines the model params, and the model checkpoint to load from. For your convenience, TensorFlow checkpoints and Gin configs for common T5 pre-trained models have been made available for use in T5X. A list of all the available pre-trained models (with model checkpoints and Gin config files) is available in the [Models](https://g3doc.corp.google.com/t5x/g3doc/models.md?cl=head) documentation.\n",
        "\n",
        "For the example run, you will use the T5 1.1 Small model. The Gin file and checkpoint for this model are defined below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afPv_yE6yWCI"
      },
      "outputs": [],
      "source": [
        "GIN_FILE_PATH = \"t5x/examples/t5/t5_1_1/small.gin\"\n",
        "MODEL_CHECKPOINT = \"gs://t5-data/pretrained_models/t5x/t5_1_1_small/checkpoint_1000000\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ao5Y3YFICO-"
      },
      "source": [
        "## Step 2: Choose a SeqIO Task/Mixture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQu8fVLcw8H5"
      },
      "source": [
        "A SeqIO Task encapsulates the data source, the preprocessing logic to be performed on the data before querying the model, the postprocessing logic to be performed on model outputs, and the metrics to be computed given the postprocessed outputs and targets. A SeqIO Mixture denotes a collection of Tasks and enables fine-tuning a model on multiple Tasks simultaneously.\n",
        "\n",
        "### Standard Tasks\n",
        "Many common datasets and benchmarks, e.g. [GLUE](https://gluebenchmark.com/), [SuperGLUE](https://super.gluebenchmark.com/), [WMT](https://www.tensorflow.org/datasets/catalog/wmt_t2t_translate), [SQUAD](https://rajpurkar.github.io/SQuAD-explorer/), [CNN/Daily Mail](https://github.com/abisee/cnn-dailymail), etc. have been implemented as SeqIO Tasks/Mixtures and can be used directly. These Tasks/Mixtures are defined in [`third_party/py/t5/data/tasks.py`](https://source.corp.google.com/piper///depot/google3/third_party/py/t5/data/tasks.py) and [`third_party/py/t5/data/mixtures.py`](https://source.corp.google.com/piper///depot/google3/third_party/py/t5/data/mixtures.py).\n",
        "\n",
        "For the example run, you will fine-tune the model on the WMT14 English to German translation benchmark, which has been implemented as the [`wmt_t2t_ende_v003`](https://source.corp.google.com/piper///depot/google3/third_party/py/t5/data/tasks.py;l=209;rcl=417815592) Task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naUoWVx9xkI7"
      },
      "outputs": [],
      "source": [
        "SEQIO_TASK = 'wmt_t2t_ende_v003'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EL96MPtxvxi"
      },
      "source": [
        "### Custom Tasks\n",
        "It is also possible to define your own custom task. See the [SeqIO documentation](https://g3doc.corp.google.com/third_party/py/seqio/google/g3doc/index.md?cl=head) for how to do this. As a note, Tasks defined using the [old T5 codebase](https://source.corp.google.com/piper///depot/google3/third_party/py/t5/data/dataset_providers.py) may also be used by T5X. If using a custom Task, you will need to follow the instructions in the \"Advanced Topics\" section at the end of this tutorial to make sure the module containing your task is included.\n",
        "\n",
        "When defining a custom task, you have the option to cache it on disk before fine-tuning. The instructions for this are [here](https://g3doc.corp.google.com/third_party/py/seqio/google/g3doc/index.md?cl=head#optional-offline-caching). Caching may improve performance for tasks with expensive pre-processing. By default, T5X expects tasks to be cached. To finetune on a task that has not been cached, set `--gin.USE_CACHED_TASKS=False`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_IJPYfmICaR"
      },
      "source": [
        "## Step 3: Write a Gin Config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKk7Hez4seiq"
      },
      "source": [
        "After choosing the pre-trained model and SeqIO Task/Mixture for your run, the next step is to configure your run using Gin. If you're not familiar with Gin, reading the [T5X Gin Primer](https://g3doc.corp.google.com/t5x/g3doc/usage/gin.md?cl=head) is recommended.\n",
        "\n",
        "T5X provides a Gin file that configures the T5X trainer for fine-tuning (located at [`p5x/configs/runs/finetune.gin`](https://source.corp.google.com/piper///depot/google3/t5x/configs/runs/finetune.gin)), and expects a few params from you. These params can be specified in a separate Gin file, or via commandline flags. Below are the required params, with the values they should be set to for the example run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYqOYnwbtP2n"
      },
      "outputs": [],
      "source": [
        "# This is the path to the pre-trained checkpoint (from Step 1). \n",
        "INITIAL_CHECKPOINT_PATH = MODEL_CHECKPOINT\n",
        "\n",
        "# This is the SeqIO Task or Mixture name to run (from Step 2). \n",
        "MIXTURE_OR_TASK_NAME = SEQIO_TASK\n",
        "\n",
        "# Number of fine-tuning steps. This includes the number of steps that the model \n",
        "# was pre-trained for, so make sure to add the step number from the \n",
        "# INITIAL_CHECKPOINT_PATH. For the example run, to fine-tune for 20,000 steps, \n",
        "# set this to 1,020,000, since the initial checkpoint is the 1,000,000th step.\n",
        "TRAIN_STEPS = 1020000\n",
        "\n",
        "# This is a dict mapping feature key to maximum int length for that feature. \n",
        "# After preprocessing, features are truncated to the provided value. \n",
        "TASK_FEATURE_LENGTHS = {\"inputs\": 256, \"targets\": 256}\n",
        "\n",
        "# A path to write fine-tuned checkpoints to. When launching using XManager, this\n",
        "# path is automatically set and can be accessed from the XManager Artifacts \n",
        "# page. When running locally using Colab/Blaze, you should explicitly pass a \n",
        "# directory. Launch commands are provided in the next step.\n",
        "MODEL_DIR = '/tmp/t5x_pretrain'\n",
        "\n",
        "# When fine-tuning a model that was pre-trained using Mesh Tensorflow (e.g. the \n",
        "# public T5 / mT5 / ByT5 models), this should be set to pretraining batch_size *\n",
        "# pretrained target_token_length. Below are the recommended values for common \n",
        "# models.\n",
        "# For T5 and T5.1.1: 2048 * 114. \n",
        "# For mT5: 1024 * 229. \n",
        "# For ByT5: 1024 * 189. \n",
        "# For MUM Base/Large/XL: 1024 * 256. \n",
        "# For MUM XXL: 1024 * 229. \n",
        "# For MUM Ace: 4096 * 229.\n",
        "LOSS_NORMALIZING_FACTOR = 233472"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv37WeXHv3p4"
      },
      "source": [
        "In addition to the above params, you will need to include `finetune.gin` and the Gin file for the pre-trained model, which for the example run is `t5_1_1/small.gin`.\n",
        "\n",
        "You will also need to import the Python module(s) that register SeqIO Tasks and Mixtures used in your run. For the example run, we add `import t5.data.tasks` since it is where `wmt_t2t_ende_v003` is registered.\n",
        "\n",
        "Note that this module must also be included as a dependency in the T5X trainer [binary](https://source.corp.google.com/piper///depot/google3/t5x/BUILD;l=76;rcl=398627055) if you want to run your experiment via commandline/XManager; this is not necessary if you plan on training via Colab. Most common Task/Mixture modules, such as this one, are already included. If your module is not included, see the \"Advanced Topics\" section at the end of this tutorial for instructions to add it.\n",
        "\n",
        "Finally, your Gin file should look like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyOqIvLmhb4U"
      },
      "outputs": [],
      "source": [
        "sample_gin_config_str = f'''\n",
        "include 't5x/configs/runs/finetune.gin'\n",
        "include '{GIN_FILE_PATH}'\n",
        "\n",
        "# Register necessary SeqIO Tasks/Mixtures.\n",
        "import t5.data.tasks\n",
        "\n",
        "MIXTURE_OR_TASK_NAME = \"{MIXTURE_OR_TASK_NAME}\"\n",
        "TASK_FEATURE_LENGTHS = {TASK_FEATURE_LENGTHS}\n",
        "TRAIN_STEPS = {TRAIN_STEPS}\n",
        "DROPOUT_RATE = 0.0\n",
        "INITIAL_CHECKPOINT_PATH = \"{INITIAL_CHECKPOINT_PATH}\"\n",
        "LOSS_NORMALIZING_FACTOR = {LOSS_NORMALIZING_FACTOR}\n",
        "MODEL_DIR = \"{MODEL_DIR}\"\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URKgIH1GICmm"
      },
      "source": [
        "## Step 4: Launch your experiment\n",
        "\n",
        "You can launch your experiment locally via the commandline or directly via Colab. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNU8-627-lDX"
      },
      "source": [
        "To launch your experiment in Colab, run the following code snippet. For the example given, you can expect to see results in ~5 mins if you are using a DRAGONFISH_DONUT runtime.\n",
        "\n",
        "\n",
        "This code snippet runs a helper function, `parse_gin_and_get_configurable_fn`; this helper takes in a function that is configurable with gin, such as the fine-tuning `train` function. It then parses the parameters of our finetuning experiment to configure the function with Gin. When run with `train` as the configurable function, it is equivalent to the T5X finetune script found in `t5x/train.py` (this is the script that will be run if you choose to train via the commandline, as described below)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2UIEyOO-qzZ"
      },
      "outputs": [],
      "source": [
        "# Call a helper function that returns a train function based on our experiment\n",
        "# parameters.\n",
        "run_finetuning = parse_gin_and_get_configurable_fn(\n",
        "    train,\n",
        "    gin_config_str=sample_gin_config_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbEjTiVmsYnJ"
      },
      "outputs": [],
      "source": [
        "# Launch experiment.\n",
        "with googlelog.Capture():\n",
        "  run_finetuning()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKPGVIYfJRFu"
      },
      "source": [
        "### On Commandline\n",
        "\n",
        "You can perform equivalent finetuning directly on the commandline as well. Please see the [Fine-tuning a Model](https://g3doc.corp.google.com/t5x/g3doc/usage/finetune.md?cl=head) g3doc for further instructions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V98JAtteUpnF"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_-YxbnBjD5k"
      },
      "source": [
        "This section outlines the steps to evaluate a model with T5X on downstream tasks defined with SeqIO. Evaluating a model with T5X consists of the following steps:\n",
        "\n",
        "1.)    Choose the model to evaluate.\n",
        "\n",
        "2.)    Choose the SeqIO Task/Mixture to evaluate the model on.\n",
        "\n",
        "3.)    Write a Gin file that configures the model, SeqIO Task/Mixture and other details of your eval run.\n",
        "\n",
        "4.)    Launch your experiment locally or on XManager.\n",
        "\n",
        "These steps are explained in detail in the following sections. We also provide an example where we evaluate the T5-1.1-Small model we fine-tuned above on the [WMT14 English to German translation benchmark](https://source.corp.google.com/piper///depot/google3/third_party/py/t5/data/tasks.py;l=209;rcl=417815592)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v72QXWMtY3O5"
      },
      "source": [
        "## Step 1: Choose a Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MDn39jajv8Z"
      },
      "source": [
        "To evaluate a model, you need a Gin config file that defines the model params, and the model checkpoint to load from. \n",
        "\n",
        "For this example, we will use the same model that we fine-tuned in the previous section. Thus, we will use the same Gin config file to define our model and we will simply update our model checkpoint to use the checkpoint we just created during fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LraYdElOUze7"
      },
      "outputs": [],
      "source": [
        "MODEL_CHECKPOINT = os.path.join(MODEL_DIR, \"checkpoint_1020000\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3xCJ5ESZZ7_"
      },
      "source": [
        "## Step 2: Choose a SeqIO Task/Mixture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E56cZ41pkKOI"
      },
      "source": [
        "A SeqIO Task encapsulates the data source, the preprocessing logic to be performed on the data before querying the model, the postprocessing logic to be performed on model outputs, and the metrics to be computed given the postprocessed outputs and targets.\n",
        "\n",
        "We will evaluate our model on the same task we fine-tuned it on, the [WMT14 English to German translation benchmark](https://source.corp.google.com/piper///depot/google3/third_party/py/t5/data/tasks.py;l=209;rcl=417815592)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKW83gr_Zc_8"
      },
      "outputs": [],
      "source": [
        "SEQIO_TASK = 'wmt_t2t_ende_v003'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCBFZBomZmlN"
      },
      "source": [
        "## Step 3: Write a Gin Config\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XuTkQcLlLD1"
      },
      "source": [
        "T5X provides a Gin file that configures the T5X eval job (located at [t5x/configs/runs/eval.gin](https://source.corp.google.com/piper///depot/google3/t5x/configs/runs/eval.gin)), and expects a few params from you. These params can be specified in a separate Gin file, or via commandline flags. Below are the required params, with the values they should be set to for the example run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3be8WX7Zovf"
      },
      "outputs": [],
      "source": [
        "# This is the path to the fine-tuned model checkpoint (from Step 1).\n",
        "CHECKPOINT_PATH = MODEL_CHECKPOINT\n",
        "\n",
        "# This is the SeqIO Task or Mixture name to run eval on (from Step 2). \n",
        "MIXTURE_OR_TASK_NAME = SEQIO_TASK\n",
        "\n",
        "# A path to write eval outputs to. When launching using XManager, this path is \n",
        "# automatically set and can be accessed from the XManager Artifacts page. When \n",
        "# running locally using Colab/Blaze, you can explicitly pass a directory. Launch\n",
        "#  commands are provided in the next step.\n",
        "EVAL_OUTPUT_DIR = \"/tmp/t5x_eval\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq3goDFel3FJ"
      },
      "source": [
        "In addition to the above params, you will need to import `eval.gin` and the Gin file for the model, which for the example run is `t5_1_1_small.gin`.\n",
        "\n",
        "You will also need to import the Python module(s) that register SeqIO Tasks and Mixtures used in your run. For the example run, we add `import t5.data.tasks` since it is where `wmt_t2t_ende_v003` is registered.\n",
        "\n",
        "Note that this module must also be included as a dependency in the T5X trainer [binary](https://source.corp.google.com/piper///depot/google3/t5x/BUILD;l=76;rcl=398627055) if you want to run your experiment via commandline/XManager; this is not necessary if you plan on training via Colab. Most common Task/Mixture modules, such as this one, are already included. If your module is not included, see the \"Advanced Topics\" section at the end of this tutorial for instructions to add it.\n",
        "\n",
        "Finally, your Gin file should look like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-upXwV4aYEg"
      },
      "outputs": [],
      "source": [
        "eval_gin_config_str = f'''\n",
        "include 't5x/configs/runs/eval.gin'\n",
        "include '{GIN_FILE_PATH}'\n",
        "\n",
        "# Register necessary SeqIO Tasks/Mixtures.\n",
        "import t5.data.tasks\n",
        "\n",
        "CHECKPOINT_PATH = '{CHECKPOINT_PATH}'\n",
        "MIXTURE_OR_TASK_NAME = '{MIXTURE_OR_TASK_NAME}'\n",
        "DROPOUT_RATE=0\n",
        "EVAL_OUTPUT_DIR=\\'{EVAL_OUTPUT_DIR}\\'\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC8DOlDfpi6f"
      },
      "source": [
        "In this example, we run the evaluation on one checkpoint. It is common to evaluate with multiple checkpoints. We provide an easy way to do so without having to recompile the model graph for each checkpoints. This is simply done by adding `utils.RestoreCheckpointConfig.mode = \"all\" ` to a gin file. Our `t5x/configs/runs/eval.gin` uses \"specific\" mode."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISbBzgZnbfv3"
      },
      "source": [
        "## Step 4: Launch your experiment\n",
        "\n",
        "You can launch your experiment locally via the commandline or directly via Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04TRl77KqmZY"
      },
      "source": [
        "To launch your experiment in Colab, run the following code snippet. For the example given, you can expect to see results in ~1 min if you are using a DRAGONFISH_DONUT runtime.\n",
        "\n",
        "This code snippet runs a helper function, `parse_gin_and_get_configurable_fn`; this helper takes in a function that is configurable with gin, such as the `evaluate` function. It then parses the parameters of our evaluation experiment to configure the function with Gin. When run with evaluate as the configurable function, it is equivalent to the T5X finetune script found in `t5x/eval.py` (this is the script that will be run if you choose to train via the commandline, as described below)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzjvlv16bjJk"
      },
      "outputs": [],
      "source": [
        "# Call a helper function that returns an evaluation function based on our experiment\n",
        "# parameters.\n",
        "run_evaluation = parse_gin_and_get_configurable_fn(evaluate,\n",
        "    gin_config_str=eval_gin_config_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQxpylXmc_Y6"
      },
      "outputs": [],
      "source": [
        "with googlelog.Capture():\n",
        "  run_evaluation()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N90vframrDEO"
      },
      "source": [
        "### On Commandline\n",
        "\n",
        "You can perform equivalent evaluation directly on the commandline as well. Please see the [Evaluating a Model](https://github.com/google-research/text-to-text-transfer-transformer/blob/main/README.mdx/usage/eval#step-4-launch-your-experiment) g3doc for further instructions.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0yCF1P236-l"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CxgbX0g38q6"
      },
      "source": [
        "T5X supports a few inference modes. Please refer to the appropriate tutorial based on your use-case:\n",
        "\n",
        "1.)     Run inference on SeqIO Tasks/Mixtures.\n",
        "\n",
        "2.)     Run inference on TF Example files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeqTKUNw4Vb5"
      },
      "source": [
        "## On SeqIO Task/Mixtures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdzqNB074xiW"
      },
      "source": [
        "To run inference on a model, you need a Gin config file that defines the model params, and the model checkpoint to load from. We will continue to use the same model as we used for evaluation. We provide the Gin config and model checkpoint for reference below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54FqgcTX5CUD"
      },
      "outputs": [],
      "source": [
        "GIN_FILE_PATH = \"t5x/examples/t5/t5_1_1/small.gin\"\n",
        "MODEL_CHECKPOINT = os.path.join(MODEL_DIR, \"checkpoint_1020000\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OmEkMgH5I7K"
      },
      "source": [
        "We must also provide a SeqIO Task/Mixture to run inference on; again, we will continue to use the [WMT14 English to German translation benchmark](https://source.corp.google.com/piper///depot/google3/third_party/py/t5/data/tasks.py;l=209;rcl=417815592)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qe2fxbNH5V_k"
      },
      "outputs": [],
      "source": [
        "SEQIO_TASK = 'wmt_t2t_ende_v003'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhRyi5xF547W"
      },
      "source": [
        "After choosing the model and SeqIO Task/Mixture for your run, the next step is to configure your run using Gin. T5X provides a Gin file that configures the T5X inference job (located at `runs/infer.gin`) to run inference on SeqIO Task/Mixtures, and expects a few params from you. Below are the required params, with the values they should be set to for the example run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1_wCSMV6BJK"
      },
      "outputs": [],
      "source": [
        "# This is the path to the fine-tuned model checkpoint (from Step 1).\n",
        "CHECKPOINT_PATH = MODEL_CHECKPOINT\n",
        "\n",
        "# This is the SeqIO Task or Mixture name to run eval on (from Step 2). \n",
        "MIXTURE_OR_TASK_NAME = SEQIO_TASK\n",
        "MIXTURE_OR_TASK_MODULE = 't5.data'\n",
        "\n",
        "# This is a dict mapping feature key to maximum length for that feature. After \n",
        "# preprocessing, features are truncated to the provided value.\n",
        "TASK_FEATURE_LENGTHS = {\"inputs\": 256, \"targets\": 256}\n",
        "\n",
        "# A path to write inference outputs to. When launching using XManager, this path is \n",
        "# automatically set and can be accessed from the XManager Artifacts page. When \n",
        "# running locally using Colab/Blaze, you can explicitly pass a directory. Launch\n",
        "# commands are provided in the next step.\n",
        "INFER_OUTPUT_DIR = \"/tmp/t5x_infer\"\n",
        "# The directory needs to exist, if it doesn't already.\n",
        "if not os.path.isdir(INFER_OUTPUT_DIR):\n",
        "  os.mkdir(INFER_OUTPUT_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PatRxtz86XHp"
      },
      "source": [
        "In addition to the above params, you will need to import `infer.gin` and the Gin file for the model, which for the example run is `t5_1_1_small.gin`.\n",
        "\n",
        "Finally, your Gin file should look like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFR0onmN6a2M"
      },
      "outputs": [],
      "source": [
        "infer_gin_config_str = f'''\n",
        "include 't5x/configs/runs/infer.gin'\n",
        "include '{GIN_FILE_PATH}'\n",
        "\n",
        "CHECKPOINT_PATH = '{CHECKPOINT_PATH}'\n",
        "MIXTURE_OR_TASK_NAME = '{MIXTURE_OR_TASK_NAME}'\n",
        "MIXTURE_OR_TASK_MODULE = '{MIXTURE_OR_TASK_MODULE}'\n",
        "TASK_FEATURE_LENGTHS = {TASK_FEATURE_LENGTHS}\n",
        "INFER_OUTPUT_DIR = '{INFER_OUTPUT_DIR}'\n",
        "DROPOUT_RATE = 0\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UunC59GL6_CJ"
      },
      "source": [
        "You can launch your experiment locally via the commandline or directly via Colab.\n",
        "\n",
        "To launch your experiment in Colab, run the following code snippet. \n",
        "\n",
        "This code snippet runs a helper function, `parse_gin_and_get_configurable_fn`; this helper takes in a function that is configurable with gin, such as the `infer` function. It then parses the parameters of our evaluation experiment to configure the function with Gin. When run with `infer` as the configurable function, it is equivalent to the T5X finetune script found in `t5x/infer.py` (this is the script that will be run if you choose to train via the commandline, as described below)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJnwxAsp7Jtu"
      },
      "outputs": [],
      "source": [
        "# Call a helper function that returns an evaluation function based on our experiment\n",
        "# parameters.\n",
        "run_inference = parse_gin_and_get_configurable_fn(infer,\n",
        "    gin_config_str=infer_gin_config_str)\n",
        "\n",
        "# Run inference.\n",
        "with googlelog.Capture():\n",
        "  run_inference()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQCO4yuZxYVS"
      },
      "source": [
        "You can perform equivalent evaluation directly on the commandline as well. Please see the [Inference on SeqIO Task/Mixtures](https://github.com/google-research/text-to-text-transfer-transformer/blob/main/README.mdx/usage/infer-seqio#step-4-launch-your-experiment) g3doc for further instructions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUK-tV_a0Oy-"
      },
      "source": [
        "## On TF Example Files\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXE3_Gc40Ugw"
      },
      "source": [
        "To run inference on a model, you need a Gin config file that defines the model params, and the model checkpoint to load from. We will continue to use the same model as we used for evaluation. We provide the Gin config and model checkpoint for reference below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Nbjjco60WWX"
      },
      "outputs": [],
      "source": [
        "GIN_FILE_PATH = \"t5x/examples/t5/t5_1_1/small.gin\"\n",
        "MODEL_CHECKPOINT = os.path.join(MODEL_DIR, \"checkpoint_1020000\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nO_BM15r0YP1"
      },
      "source": [
        "T5X supports running inference on `tfrecord`, `recordio` and `sstable` files containing TF Examples. For the example run, you will run inference on `tfrecord` files containing the '`natural_questions_open`' dataset located here: `/path/to/tfds/data/dir/natural_questions_open/1.0.0/natural_questions_open-validation.tfrecord*`. Here's an example of a single row of data from this file (you can explore this file further using GQUI):\n",
        "\n",
        "```\n",
        "{ # (tensorflow.Example) size=101B\n",
        "  features: { # (tensorflow.Features) size=99B\n",
        "    feature: { # (tensorflow.Features.FeatureEntry) size=27B\n",
        "      key: \"answer\" # size=6\n",
        "      value: { # (tensorflow.Feature) size=17B\n",
        "        bytes_list: { # (tensorflow.BytesList) size=15B\n",
        "          value: [ \"Jason Flemyng\" ] # size=13\n",
        "        } # features.feature[0].value.bytes_list\n",
        "      } # features.feature[0].value\n",
        "    } # features.feature[0]\n",
        "    feature: { # (tensorflow.Features.FeatureEntry) size=68B\n",
        "      key: \"question\" # size=8\n",
        "      value: { # (tensorflow.Feature) size=56B\n",
        "        bytes_list: { # (tensorflow.BytesList) size=54B\n",
        "          value: [ \"who played hyde in league of extraordinary gentlemen\" ] # size=52\n",
        "        } # features.feature[1].value.bytes_list\n",
        "      } # features.feature[1].value\n",
        "    } # features.feature[1]\n",
        "  } # features\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1n9cc0l60sLr"
      },
      "outputs": [],
      "source": [
        "TF_RECORD_FILEPATH = '/path/to/tfds/data/dir/natural_questions_open/1.0.0/natural_questions_open-validation.tfrecord*'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZU4cKON0pSk"
      },
      "source": [
        "After choosing the model and file source for your run, the next step is to configure your run using Gin. T5X provides a Gin file that configures the T5X inference job (located at `t5x/configs/runs/infer_from_tfexample_file.gin`) to run inference on TF Example files, and expects a few params from you. Below are the required params, with the values they should be set to for the example run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChMkH5yM0_-x"
      },
      "outputs": [],
      "source": [
        "# This is the path to the model checkpoint.\n",
        "CHECKPOINT_PATH = MODEL_CHECKPOINT\n",
        "\n",
        "# This is a list of paths or glob patterns to read TF Examples from. \n",
        "TF_EXAMPLE_FILE_PATHS = [TF_RECORD_FILEPATH]\n",
        "\n",
        "# This is the TF Example file format. Currently supported file formats are \n",
        "# tfrecord, recordio and sstable.\n",
        "TF_EXAMPLE_FILE_TYPE = 'tfrecord'\n",
        "\n",
        "# This is a dict mapping feature key to maximum int length for that feature. The\n",
        "# TF Example features are truncated to the provided value. \n",
        "FEATURE_LENGTHS = {'inputs': 38, 'targets': 18}\n",
        "\n",
        "# A path to write inference outputs to. When launching using XManager, this path is \n",
        "# automatically set and can be accessed from the XManager Artifacts page. When \n",
        "# running locally using Colab/Blaze, you can explicitly pass a directory. Launch\n",
        "# commands are provided in the next step.\n",
        "INFER_OUTPUT_DIR = \"/tmp/t5x_infer\"\n",
        "# The directory needs to exist, if it doesn't already.\n",
        "if not os.path.isdir(INFER_OUTPUT_DIR):\n",
        "  os.mkdir(INFER_OUTPUT_DIR)\n",
        "\n",
        "MIXTURE_OR_TASK_NAME = infer_script.create_task_from_tfexample_file(paths=TF_EXAMPLE_FILE_PATHS, \n",
        "                                               file_type=TF_EXAMPLE_FILE_TYPE,\n",
        "                                               inputs_key='questions', \n",
        "                                               targets_key=None,\n",
        "                                               features=FEATURE_LENGTHS)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4-3E5BB1hXC"
      },
      "source": [
        "In addition to the above params, ou may also need to override the `create_task_from_tfexample_file.inputs_key` param based on the data format (it is set to 'inputs' by default. You will also need to import `infer_from_tfexample_file.gin` and the Gin file for the model, which for the example run is `t5_1_1_small.gin`.\n",
        "\n",
        "For the purposes of this colab, we must make a few small edits to `infer_from_tfexample_file.gin`. Namely, we must replace all imports that refer to `__main__` with references to `t5x.infer`. We thus write `infer_from_tfexample_file.gin` to a temporary file where we can make these edits, using the helper function below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ou75Av-s9nkS"
      },
      "outputs": [],
      "source": [
        "def replace_main_in_config(config_filename, tmp_output_dir):\n",
        "  '''\n",
        "  Replace imports that refer to `__main__` with `t5x.infer`.\n",
        "  '''\n",
        "  original_gin_filepath = f'/google_src/head/depot/google3/t5x/configs/runs/{config_filename}'\n",
        "  temporary_gin_filepath = os.path.join(tmp_output_dir, f\"tmp_{config_filename}\")\n",
        "  with gfile.Open(original_gin_filepath, \"rt\") as original_gin_file:\n",
        "    with open(temporary_gin_filepath, \"w\") as temporary_gin_file:\n",
        "      for line in original_gin_file.readlines():\n",
        "        line = re.sub(\"__main__\", \"t5x.infer\", line)\n",
        "        temporary_gin_file.write(line)\n",
        "  return temporary_gin_filepath\n",
        "\n",
        "temporary_gin_filepath = replace_main_in_config(\"infer_from_tfexample_file.gin\", INFER_OUTPUT_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6f_JK6r-05K"
      },
      "source": [
        "Finally, your Gin file should look like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z79aQ8WF1wsr"
      },
      "outputs": [],
      "source": [
        "infer_gin_config_str = f'''\n",
        "include '{temporary_gin_filepath}'\n",
        "include '{GIN_FILE_PATH}'\n",
        "\n",
        "CHECKPOINT_PATH = '{CHECKPOINT_PATH}'\n",
        "TF_EXAMPLE_FILE_PATHS = {TF_EXAMPLE_FILE_PATHS}\n",
        "TF_EXAMPLE_FILE_TYPE = '{TF_EXAMPLE_FILE_TYPE}'\n",
        "FEATURE_LENGTHS = {FEATURE_LENGTHS}\n",
        "INFER_OUTPUT_DIR = '{INFER_OUTPUT_DIR}'\n",
        "DROPOUT_RATE = 0\n",
        "create_task_from_tfexample_file.inputs_key = 'question'\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rh_4_u0h2dGR"
      },
      "source": [
        "You can launch your experiment locally via the commandline or directly via Colab.\n",
        "\n",
        "To launch your experiment in Colab, run the following code snippet.\n",
        "\n",
        "This code snippet runs a helper function, `parse_gin_and_get_configurable_fn`; this helper takes in a function that is configurable with gin, such as the infer function. It then parses the parameters of our evaluation experiment to configure the function with Gin. When run with `infer` as the configurable function, it is equivalent to the T5X finetune script found in `t5x/infer.py` (this is the script that will be run if you choose to train via the commandline, as described below)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bW9kLTO2ltm"
      },
      "outputs": [],
      "source": [
        "# Call a helper function that returns an evaluation function based on our experiment\n",
        "# parameters.\n",
        "run_inference = parse_gin_and_get_configurable_fn(infer,\n",
        "    gin_config_str=infer_gin_config_str)\n",
        "\n",
        "# Run inference.\n",
        "with googlelog.Capture():\n",
        "  run_inference()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZX5VodbxuTb"
      },
      "source": [
        "You can perform equivalent evaluation directly on the commandline as well. Please see the [Inference on TF Example Files](https://github.com/google-research/text-to-text-transfer-transformer/blob/main/README.mdx/usage/infer-files#step-4-launch-your-experiment) g3doc for further instructions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Elvp4380yHvr"
      },
      "source": [
        "# [Advanced] Pre-training from Scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-esmNEln_MDm"
      },
      "source": [
        "Pretraining a model with T5X consists of the following steps:\n",
        "\n",
        "1.)    Choose the model architecture.\n",
        "\n",
        "2.)    Choose the SeqIO Task/Mixture to for training.\n",
        "\n",
        "3.)    Write a Gin file that configures the model, SeqIO Task/Mixture and other details of your pretraining run.\n",
        "\n",
        "4.)    Launch your experiment locally or on XManager.\n",
        "\n",
        "These steps are explained in detail in the following sections. An example run that trains a T5 1.1 Small checkpoint from scratch on the C4 dataset using the span corruption pretraining objective is also showcased."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_i5NalG_bRk"
      },
      "source": [
        "## Step 1: Choose a model architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaWbpAku_-sG"
      },
      "source": [
        "To train a model, you need a Gin config file that defines the model params. For your convenience, Gin configs for common models have been made available for use in T5X. You can find a list of these models and their Gin locations in the [T5X g3doc](https://github.com/google-research/text-to-text-transfer-transformer/blob/main/README.mdx/usage/pretrain#step-1-choose-a-model-architecture).\n",
        "\n",
        "For the example run, you will use the T5 1.1 Small model. The Gin file for this model is located at `t5x/examples/t5/t5_1_1/small.gin`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mz2Wg-p-AZiW"
      },
      "outputs": [],
      "source": [
        "GIN_FILE_PATH = 't5x/examples/t5/t5_1_1/small.gin'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9v8HCpQAgqu"
      },
      "source": [
        "## Step 2: Choose a SeqIO Task/Mixture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sFUWesKArfL"
      },
      "source": [
        "A SeqIO Task encapsulates the data source, the preprocessing logic to be performed on the data before querying the model, the postprocessing logic to be performed on model outputs, and the metrics to be computed given the postprocessed outputs and targets. A SeqIO Mixture denotes a collection of Tasks and enables pretraining a model on multiple Tasks simultaneously.\n",
        "\n",
        "For the example run, you will train the model on [`c4_v220_span_corruption`](https://source.corp.google.com/piper///depot/google3/third_party/py/t5/data/tasks.py;l=42;rcl=370153959) task that implements the span corruption pretraining objective using the C4 dataset. This is the final pretraining Task used in the T5 paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxw11Cr0BUGt"
      },
      "outputs": [],
      "source": [
        "SEQIO_TASK = 'c4_v220_span_corruption'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLsgevTRBvYy"
      },
      "source": [
        "## Step 3: Write a Gin Config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0rOstgHBx40"
      },
      "source": [
        "After choosing the model architecture and SeqIO Task/Mixture for your run, the next step is to configure your run using Gin. T5X provides a Gin file that configures the T5X trainer for pretraining (located at `runs/pretrain.gin`), and expects a few params from you. These params can be specified in a separate Gin file, or via commandline flags. Below are the required params, with the values they should be set to for the example run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2frJNuvCjxd"
      },
      "outputs": [],
      "source": [
        "# Number of training steps.\n",
        "TRAIN_STEPS = 100000\n",
        "\n",
        "# This is the SeqIO Task or Mixture name to run (from Step 2).\n",
        "MIXTURE_OR_TASK_NAME = SEQIO_TASK\n",
        "\n",
        "# This is a dict mapping feature key to maximum int length for that feature. \n",
        "# After preprocessing, features are truncated to the provided value.\n",
        "TASK_FEATURE_LENGTHS = {\"inputs\": 512, \"targets\": 114}\n",
        "\n",
        "# A path to write pretrained checkpoints to. When launching using XManager, this\n",
        "# path is automatically set and can be accessed from the XManager Artifacts \n",
        "# page. When running locally using Colab/Blaze, you can explicitly pass a \n",
        "# directory. Launch commands are provided in the next step.\n",
        "MODEL_DIR = \"/tmp/pretrain-round-2\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgLXxSfLDCqR"
      },
      "source": [
        "In addition to the above params, you will need to import `pretrain.gin` and the Gin file for the pretrained model, which for the example run is `t5_1_1/small.gin`. You will also need to import the Python module(s) that register SeqIO Tasks and Mixtures used in your run. For the example run, we add `import t5.data.mixtures`.\n",
        "\n",
        "Finally, your Gin file should look like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtVjSM28DN36"
      },
      "outputs": [],
      "source": [
        "pretrain_gin_config_str = f'''\n",
        "include '{GIN_FILE_PATH}'\n",
        "include 't5x/configs/runs/pretrain.gin'\n",
        "\n",
        "# Register necessary SeqIO Tasks/Mixtures.\n",
        "import t5.data.mixtures\n",
        "\n",
        "MIXTURE_OR_TASK_NAME = \"{MIXTURE_OR_TASK_NAME}\"\n",
        "TASK_FEATURE_LENGTHS = {TASK_FEATURE_LENGTHS}\n",
        "TRAIN_STEPS = {TRAIN_STEPS}\n",
        "MODEL_DIR = \"{MODEL_DIR}\"\n",
        "DROPOUT_RATE = 0.0\n",
        "BATCH_SIZE = 256\n",
        "partitioning.PjitPartitioner.num_partitions=2\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3xlIj8MDxeD"
      },
      "source": [
        "## Step 4: Launch your experiment\n",
        "\n",
        "You can launch your experiment locally via the commandline or directly via Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MX3v74vBD4Me"
      },
      "source": [
        "To launch your experiment in Colab, run the following code snippet. For the example given, you can expect to see results in ~X mins if you are using a DRAGONFISH_DONUT runtime.\n",
        "\n",
        "This code snippet runs a helper function, `parse_gin_and_get_configurable_fn`; this helper takes in a function that is configurable with gin, such as the pre-tuning `train` function. It then parses the parameters of our pre-training experiment to configure the function with Gin. When run with `train` as the configurable function, it is equivalent to the T5X pre-training script found in `t5x/train.py` (this is the script that will be run if you choose to train via the commandline, as described below)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_uOLqB7EIdQ"
      },
      "outputs": [],
      "source": [
        "# Call a helper function that returns a train function based on our experiment\n",
        "# parameters.\n",
        "run_pretraining = parse_gin_and_get_configurable_fn(\n",
        "    train,\n",
        "    gin_config_str=pretrain_gin_config_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZ4wxIRLIqxj"
      },
      "outputs": [],
      "source": [
        "# Launch experiment.\n",
        "with googlelog.Capture():\n",
        "  run_pretraining()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yE1_Boq_vhea"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "print(jax.devices())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJeOCJBxPuMZ"
      },
      "source": [
        "# Loading a Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCLAwV3vQXUV"
      },
      "source": [
        "## With Gin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrikJ9O3Ptdb"
      },
      "source": [
        "Let's define our Gin config and gin search paths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzjYpBOmzKmN"
      },
      "outputs": [],
      "source": [
        "# Gin Config\n",
        "gin_config = \"\"\"\n",
        "include 't5x/examples/t5/t5_1_1/base.gin'  # imports vocab, optimizer and model.\n",
        "DROPOUT_RATE = 0.0\n",
        "# ------------------- Network specification overrides --------------------------\n",
        "network.Transformer.config = @network.T5Config()\n",
        "network.T5Config:\n",
        "  emb_dim = 512\n",
        "  num_heads = 6\n",
        "  num_encoder_layers = 8\n",
        "  num_decoder_layers = 8\n",
        "  head_dim = 64\n",
        "  mlp_dim = 1024\n",
        "\"\"\"\n",
        "\n",
        "gin_path = \"/google_src/head/depot/google3/\"\n",
        "gin_search_files = [\n",
        "    \"\",\n",
        "    \"t5x/\",\n",
        "    \"t5x/examples/t5/t5_1_1/small.gin\",\n",
        "    \"t5x/configs/runs/finetune.gin\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scavKUktQKBr"
      },
      "source": [
        "Next, let's parse this config."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgkbnMJwHuDz"
      },
      "outputs": [],
      "source": [
        "for filepath in gin_search_files:\n",
        "  abs_filepath = gin_path + filepath\n",
        "  gin.add_config_file_search_path(abs_filepath)\n",
        "  print(f\"Added {abs_filepath} to the search list.\")\n",
        "\n",
        "gin.parse_config(gin_config)\n",
        "gin.finalize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCkDaxmeQMsY"
      },
      "source": [
        "Finally, let's test that we've parsed our gin file correctly by querying for some test parameters and loading our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtXT_QoZMfjL"
      },
      "outputs": [],
      "source": [
        "print(gin.query_parameter('network.T5Config.emb_dim'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "634c87iCOknU"
      },
      "outputs": [],
      "source": [
        "model = gin.get_configurable(\"MODEL/macro\")\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jj2ZlNgrGX6w"
      },
      "outputs": [],
      "source": [
        "GIN_FILE_PATH = \"t5x/examples/t5/t5_1_1/small.gin\"\n",
        "MODEL_CHECKPOINT = \"gs://t5-data/pretrained_models/t5x/t5_1_1_small\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGaJdKW7G-tY"
      },
      "outputs": [],
      "source": [
        "def restore_from_checkpoint(checkpoint_path):\n",
        "    \"\"\"Restore training state from checkpoint.\"\"\"\n",
        "    train_state_initializer = t5x.utils.TrainStateInitializer(\n",
        "      optimizer_def=model.optimizer_def,\n",
        "      init_fn=model.get_initial_variables,\n",
        "      input_shapes=self.input_shapes,\n",
        "      partitioner=self.partitioner)\n",
        "\n",
        "    restore_checkpoint_cfg = t5x.utils.RestoreCheckpointConfig(\n",
        "        path=checkpoint_path, mode='specific', dtype='float32')\n",
        "\n",
        "    train_state_axes = train_state_initializer.train_state_axes\n",
        "    self._predict_fn = self._get_predict_fn(train_state_axes)\n",
        "    self._train_state = train_state_initializer.from_checkpoint_or_scratch(\n",
        "        [restore_checkpoint_cfg], init_rng=jax.random.PRNGKey(0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "je0T07apQxbi"
      },
      "source": [
        "## Without Gin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMGGrL2uQzlC"
      },
      "outputs": [],
      "source": [
        "t5_config = network.T5Config(\n",
        "      vocab_size=32128,\n",
        "      dtype='bfloat16',\n",
        "      emb_dim=768,\n",
        "      num_heads=12,\n",
        "      num_encoder_layers=12,\n",
        "      num_decoder_layers=12,\n",
        "      head_dim=64,\n",
        "      mlp_dim=2048,\n",
        "      mlp_activations=('gelu', 'linear'),\n",
        "      dropout_rate=0.0,\n",
        "      logits_via_embedding=False)\n",
        "module = network.Transformer(config=t5_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NP4zAMXxXk7T"
      },
      "outputs": [],
      "source": [
        "model = t5x.models.EncoderDecoderModel(\n",
        "    module=module,\n",
        "    input_vocabulary=t5.data.get_default_vocabulary(),\n",
        "    output_vocabulary=t5.data.get_default_vocabulary(),\n",
        "    optimizer_def=t5x.adafactor.Adafactor(decay_rate=0.8,step_offset=0),\n",
        "    decode_fn=functools.partial(t5x.decoding.temperature_sample, temperature=1.0, topk=40)\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "PCVAdUsH3DFM",
        "gVgMKSNkIB4L",
        "8ao5Y3YFICO-",
        "8_IJPYfmICaR",
        "URKgIH1GICmm",
        "yKPGVIYfJRFu",
        "V98JAtteUpnF",
        "v72QXWMtY3O5",
        "O3xCJ5ESZZ7_",
        "DCBFZBomZmlN",
        "ISbBzgZnbfv3",
        "W0yCF1P236-l",
        "eeqTKUNw4Vb5",
        "zUK-tV_a0Oy-",
        "H_i5NalG_bRk",
        "G9v8HCpQAgqu",
        "cLsgevTRBvYy",
        "fJeOCJBxPuMZ"
      ],
      "last_runtime": {
        "build_target": "//learning/deepmind/public/tools/ml_python:ml_notebook",
        "kind": "private"
      },
      "name": "[DRAFT] T5X Introductory Colab",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1rA8bgO2bJRoebAuS96Ji0RUhnawgBY4i",
          "timestamp": 1650476728182
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
